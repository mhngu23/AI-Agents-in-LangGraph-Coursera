{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3dbb256a-185c-46e0-bf8e-4ffc6a9776bb-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}\n",
      "Back to the model!\n",
      "[ToolMessage(content=\"[{'url': 'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=October', 'content': 'weather25.com\\\\nSearch\\\\nweather in United States\\\\nRemove from your favorite locations\\\\nAdd to my locations\\\\nShare\\\\nweather in United States\\\\n\\\\n# San Francisco weather in October 2025\\\\n\\\\nClear\\\\nSunny\\\\nFog\\\\nClear\\\\nClear\\\\nClear\\\\nPartly cloudy\\\\nPatchy rain possible\\\\nPatchy rain possible\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\n\\\\n## The average weather in San Francisco in October\\\\n\\\\nThe temperatures in San Francisco in October are comfortable with low of 13°C and and high up to 23°C. [...] | 19 Cloudy 21° /14° | 20 Sunny 21° /14° | 21 Partly cloudy 20° /14° | 22 Sunny 19° /14° | 23 Sunny 18° /13° | 24 Sunny 19° /13° | 25 Cloudy 19° /14° |\\\\n| 26 Sunny 19° /13° | 27 Sunny 19° /12° | 28 Sunny 27° /11° | 29 Sunny 22° /15° | 30 Fog 14° /13° | 31 Sunny 18° /13° |  | [...] Sunny\\\\nSunny\\\\nSunny\\\\nPartly cloudy\\\\nSunny\\\\nPartly cloudy\\\\nPartly cloudy\\\\nOvercast\\\\nPartly cloudy\\\\nSunny\\\\nPartly cloudy\\\\nPartly cloudy\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nCloudy\\\\nSunny\\\\nPartly cloudy\\\\nSunny\\\\nSunny\\\\nSunny\\\\nCloudy\\\\nSunny\\\\nSunny\\\\nSunny\\\\nSunny\\\\nFog\\\\nSunny\\\\n\\\\n## Explore the weather in San Francisco in other months\\\\n\\\\n## San Francisco annual weather'}, {'url': 'https://www.accuweather.com/en/us/san-francisco/94103/october-weather/347629', 'content': '# San Francisco, CA\\\\n\\\\nSan Francisco\\\\n\\\\nCalifornia\\\\n\\\\n## Around the Globe\\\\n\\\\nAround the Globe\\\\n\\\\n### Hurricane Tracker\\\\n\\\\n### Severe Weather\\\\n\\\\n### Radar & Maps\\\\n\\\\n### News & Features\\\\n\\\\n### Astronomy\\\\n\\\\n### Business\\\\n\\\\n### Climate\\\\n\\\\n### Health\\\\n\\\\n### Recreation\\\\n\\\\n### Sports\\\\n\\\\n### Travel\\\\n\\\\n### Warnings\\\\n\\\\n### Data Suite\\\\n\\\\n### Forensics\\\\n\\\\n### Advertising\\\\n\\\\n### Superior Accuracy™\\\\n\\\\n### Video\\\\n\\\\n### Winter Center\\\\n\\\\n## Monthly\\\\n\\\\n## October\\\\n\\\\n## 2025\\\\n\\\\n## Daily\\\\n\\\\n## Temperature Graph\\\\n\\\\n## Further Ahead\\\\n\\\\nFurther Ahead\\\\n\\\\n### November 2025 [...] ### December 2025\\\\n\\\\n### January 2026\\\\n\\\\n## Around the Globe\\\\n\\\\nAround the Globe\\\\n\\\\n### Hurricane Tracker\\\\n\\\\n### Severe Weather\\\\n\\\\n### Radar & Maps\\\\n\\\\n### News\\\\n\\\\n### Video\\\\n\\\\n### Winter Center\\\\n\\\\nTop Stories\\\\n\\\\nHurricane\\\\n\\\\nCategory 5 Melissa to unleash life-threatening catastrophe in Jamaica\\\\n\\\\n46 minutes ago\\\\n\\\\nWeather Forecasts\\\\n\\\\nWeather troubles brewing for some trick-or-treaters through Halloween\\\\n\\\\n4 hours ago\\\\n\\\\nHurricane\\\\n\\\\nMelissa nears landfall in Jamaica as strongest hurricane of 2025\\\\n\\\\n26 minutes ago\\\\n\\\\nHurricane [...] Hurricane Melissa to blast Cuba, Bahamas before turning toward Bermuda\\\\n\\\\n44 minutes ago\\\\n\\\\nHurricane\\\\n\\\\nJamaica has rich hurricane history, but has avoided most powerful stor...\\\\n\\\\n1 day ago\\\\n\\\\nFeatured Stories\\\\n\\\\nTravel\\\\n\\\\nAir traffic control staffing problems spiked over the weekend\\\\n\\\\n1 day ago\\\\n\\\\nWeather News\\\\n\\\\nBible found opened to Psalm 106 and 107 one of few objects to survive ...\\\\n\\\\n1 day ago\\\\n\\\\nHurricane\\\\n\\\\nThe historic hurricane that unleashed a blizzard\\\\n\\\\n1 day ago\\\\n\\\\nWeather News'}]\", name='tavily_search_results_json', tool_call_id='call_bmfLa92f6oAIKN9KvXtqbKDz')]\n",
      "[AIMessage(content=\"I couldn't find the real-time weather for San Francisco at the moment. You might want to check a weather website or app for live updates.\", response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 1004, 'total_tokens': 1033, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_65564d8ba5', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0e9906a-3732-43ab-9a8b-5dff15126397-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lHKBApysD6DmKfU6fHh9VHJ8', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 1045, 'total_tokens': 1067, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_65564d8ba5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-acb1e406-1970-48ab-9f01-f4a84f5ad338-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_lHKBApysD6DmKfU6fHh9VHJ8'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_lHKBApysD6DmKfU6fHh9VHJ8'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://www.weather25.com/north-america/usa/california/los-angeles?page=month&month=October', 'content': 'weather25.com\\\\nSearch\\\\nweather in United States\\\\nRemove from your favorite locations\\\\nAdd to my locations\\\\nShare\\\\nweather in United States\\\\n\\\\n# Los Angeles weather in October 2025\\\\n\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\nOvercast\\\\nClear\\\\nPatchy rain possible\\\\nSunny\\\\nClear\\\\nClear\\\\nClear\\\\nClear\\\\n\\\\n## The average weather in Los Angeles in October\\\\n\\\\nThe temperatures in Los Angeles in October are comfortable with low of 18°C and and high up to 27°C. [...] | December | 19° / 11° | 3 | 28 | 0 | 66 mm | Good | Los Angeles in December | [...] | 19 Sunny 28° /19° | 20 Sunny 28° /19° | 21 Sunny 27° /19° | 22 Sunny 24° /18° | 23 Partly cloudy 24° /17° | 24 Sunny 24° /17° | 25 Sunny 23° /17° |\\\\n| 26 Sunny 24° /17° | 27 Sunny 23° /16° | 28 Sunny 38° /14° | 29 Sunny 35° /20° | 30 Sunny 33° /20° | 31 Sunny 26° /19° |  |'}, {'url': 'https://www.accuweather.com/en/us/los-angeles/90012/october-weather/347625', 'content': '# Los Angeles, CA\\\\n\\\\nLos Angeles\\\\n\\\\nCalifornia\\\\n\\\\n## Around the Globe\\\\n\\\\nAround the Globe\\\\n\\\\n### Hurricane Tracker\\\\n\\\\n### Severe Weather\\\\n\\\\n### Radar & Maps\\\\n\\\\n### News & Features\\\\n\\\\n### Astronomy\\\\n\\\\n### Business\\\\n\\\\n### Climate\\\\n\\\\n### Health\\\\n\\\\n### Recreation\\\\n\\\\n### Sports\\\\n\\\\n### Travel\\\\n\\\\n### Warnings\\\\n\\\\n### Data Suite\\\\n\\\\n### Forensics\\\\n\\\\n### Advertising\\\\n\\\\n### Superior Accuracy™\\\\n\\\\n### Video\\\\n\\\\n### Winter Center\\\\n\\\\n## Monthly\\\\n\\\\n## October\\\\n\\\\n## 2025\\\\n\\\\n## Daily\\\\n\\\\n## Temperature Graph\\\\n\\\\n## Further Ahead\\\\n\\\\nFurther Ahead\\\\n\\\\n### November 2025 [...] ### December 2025\\\\n\\\\n### January 2026\\\\n\\\\n## Around the Globe\\\\n\\\\nAround the Globe\\\\n\\\\n### Hurricane Tracker\\\\n\\\\n### Severe Weather\\\\n\\\\n### Radar & Maps\\\\n\\\\n### News\\\\n\\\\n### Video\\\\n\\\\n### Winter Center\\\\n\\\\nTop Stories\\\\n\\\\nHurricane\\\\n\\\\nCategory 5 Melissa to unleash life-threatening catastrophe in Jamaica\\\\n\\\\n10 minutes ago\\\\n\\\\nWeather Forecasts\\\\n\\\\nWeather troubles brewing for some trick-or-treaters through Halloween\\\\n\\\\n4 hours ago\\\\n\\\\nHurricane\\\\n\\\\nMelissa nears landfall in Jamaica as strongest hurricane of 2025\\\\n\\\\n12 minutes ago\\\\n\\\\nHurricane [...] Hurricane Melissa to blast Cuba, Bahamas before turning toward Bermuda\\\\n\\\\n49 minutes ago\\\\n\\\\nHurricane\\\\n\\\\nJamaica has rich hurricane history, but has avoided most powerful stor...\\\\n\\\\n1 day ago\\\\n\\\\nFeatured Stories\\\\n\\\\nTravel\\\\n\\\\nAir traffic control staffing problems spiked over the weekend\\\\n\\\\n1 day ago\\\\n\\\\nWeather News\\\\n\\\\nBible found opened to Psalm 106 and 107 one of few objects to survive ...\\\\n\\\\n1 day ago\\\\n\\\\nHurricane\\\\n\\\\nThe historic hurricane that unleashed a blizzard\\\\n\\\\n1 day ago\\\\n\\\\nWeather News'}]\", name='tavily_search_results_json', tool_call_id='call_lHKBApysD6DmKfU6fHh9VHJ8')]}\n",
      "{'messages': [AIMessage(content=\"I couldn't find the real-time weather for Los Angeles at the moment. You might want to check a weather website or app for live updates.\", response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 1824, 'total_tokens': 1853, 'prompt_tokens_details': {'cached_tokens': 1024, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_65564d8ba5', 'finish_reason': 'stop', 'logprobs': None}, id='run-5640c45b-7c25-4607-8fe7-152ab642e78a-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Based on the general climate data for October, Los Angeles tends to be warmer than San Francisco. Los Angeles typically has temperatures with lows of around 18°C (64°F) and highs up to 27°C (81°F). In contrast, San Francisco generally experiences lows of around 13°C (55°F) and highs up to 23°C (73°F). Therefore, Los Angeles is usually warmer than San Francisco.', response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 1865, 'total_tokens': 1951, 'prompt_tokens_details': {'cached_tokens': 1792, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_65564d8ba5', 'finish_reason': 'stop', 'logprobs': None}, id='run-4a7a9836-1a61-4ef0-8e9d-2c980fd130a7-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"Could you please clarify what you're comparing to determine which is warmer? Are you comparing two specific locations, types of clothing, materials, or something else? Let me know so I can provide the appropriate information.\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 149, 'total_tokens': 192, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-c6b10b47-3f2c-4c9c-9f6a-f82751a739a4-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens\n",
    "⚡ Why token streaming is often preferred\n",
    "1. Faster perceived latency\n",
    "\n",
    "Token streaming gives the illusion of speed.\n",
    "The first token might appear after 200 ms instead of waiting 5 seconds for the full message.\n",
    "\n",
    "Users can start reading or reacting immediately.\n",
    "\n",
    "2. Better interactivity / responsiveness\n",
    "\n",
    "With token streaming, your app can:\n",
    "\n",
    "Interrupt or stop generation mid-way (like “Stop generating” in ChatGPT)\n",
    "\n",
    "Display live UI updates (progress indicators, typing effect)\n",
    "\n",
    "Dynamically adjust tone, prompt, or tool usage as tokens arrive\n",
    "\n",
    "This is essential for:\n",
    "\n",
    "Chatbots\n",
    "\n",
    "Voice assistants\n",
    "\n",
    "Realtime coding assistants\n",
    "\n",
    "Live reasoning/chain-of-thought visualizations\n",
    "\n",
    "\n",
    "3. Granular control and analytics\n",
    "\n",
    "You can:\n",
    "\n",
    "Capture per-token timing for latency profiling\n",
    "\n",
    "Analyze or censor tokens before displaying them\n",
    "\n",
    "Log token-by-token deltas for replay, debugging, or incremental saving (using async memory savers like AsyncSqliteSaver)\n",
    "\n",
    "4. Scalable architecture for long outputs\n",
    "\n",
    "Token streaming allows you to process and transmit large outputs incrementally, without storing the entire message in memory at once.\n",
    "That means:\n",
    "\n",
    "Lower memory footprint\n",
    "\n",
    "More robust for long documents or model responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d709fb4",
   "metadata": {},
   "source": [
    "💬 Why you might still choose message streaming\n",
    "\n",
    "Message-level streaming (or non-streaming) is simpler when:\n",
    "\n",
    "You don’t need real-time updates.\n",
    "\n",
    "You’re dealing with short or predictable outputs.\n",
    "\n",
    "You prefer atomic transactions (e.g., you only save once the message is complete).\n",
    "\n",
    "The client (UI) or backend doesn’t support streaming sockets or async pipelines.\n",
    "\n",
    "💡 When you’d prefer message streaming\n",
    "1. Backend pipelines / APIs\n",
    "\n",
    "If you’re building an API endpoint that:\n",
    "\n",
    "Takes a request,\n",
    "\n",
    "Generates a model response,\n",
    "\n",
    "Returns it as a JSON or text payload,\n",
    "\n",
    "then message streaming simplifies everything.\n",
    "\n",
    "Example:\n",
    "A backend that powers a chatbot UI (where the client doesn’t support websockets or streams) — you just send the full message once it’s done.\n",
    "\n",
    "Why:\n",
    "\n",
    "Easier to manage errors (no partial responses)\n",
    "\n",
    "Works well with HTTP/REST (single response)\n",
    "\n",
    "Easier logging and retry logic\n",
    "\n",
    "✅ Example use case:\n",
    "\n",
    "An internal ML microservice that classifies or summarizes input text and returns the full output in one call.\n",
    "\n",
    "2. Batch or offline processing\n",
    "\n",
    "When you’re generating text for many samples at once — e.g.:\n",
    "\n",
    "Summarizing thousands of documents,\n",
    "\n",
    "Labeling data,\n",
    "\n",
    "Generating synthetic datasets,\n",
    "\n",
    "streaming token-by-token doesn’t help — you just want the final outputs.\n",
    "\n",
    "✅ Example use case:\n",
    "\n",
    "Generate product descriptions for a catalog of 10,000 items overnight.\n",
    "\n",
    "3. Evaluation and scoring tasks\n",
    "\n",
    "If your system compares whole responses (e.g., BLEU, ROUGE, or factuality evaluation), it needs complete outputs.\n",
    "\n",
    "Why: Partial outputs have no evaluation meaning.\n",
    "\n",
    "✅ Example use case:\n",
    "\n",
    "Comparing full model completions in a research experiment or RLHF dataset.\n",
    "\n",
    "4. Deterministic transaction workflows\n",
    "\n",
    "If your model’s response triggers a single atomic action — e.g.:\n",
    "\n",
    "Execute a SQL query\n",
    "\n",
    "Make an API call\n",
    "\n",
    "Send an email\n",
    "\n",
    "you must ensure you have the entire valid output before acting.\n",
    "Streaming partial tokens could be dangerous or invalid.\n",
    "\n",
    "✅ Example use case:\n",
    "\n",
    "An AI agent that outputs structured JSON for automation (you can’t parse half a JSON).\n",
    "\n",
    "5. Simpler architecture / less async complexity\n",
    "\n",
    "Token streaming requires async event loops, WebSockets, or streaming callbacks.\n",
    "If your infrastructure doesn’t support that (e.g., synchronous web servers, CLI tools, or certain cloud environments), message streaming is more stable.\n",
    "\n",
    "✅ Example use case:\n",
    "\n",
    "A simple Flask API or batch script running model completions in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "# This is because you dont want to block the actual text generation. \n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_GiHnpbt7P6kuX4g2n6imqDXI'}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
